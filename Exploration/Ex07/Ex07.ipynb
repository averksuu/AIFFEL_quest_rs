{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Ï†ÑÏ≤òÎ¶¨"
      ],
      "metadata": {
        "id": "wYeonRyi2bB-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "B72FKWGGtyiH"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "def normalize_text(s):\n",
        "  if not isinstance(s,str):\n",
        "    s=str(s)\n",
        "  s=s.lower()\n",
        "  s=re.sub(r\"[^Í∞Ä-Ìû£a-z0-9.,?!\\s]\", \" \", s)\n",
        "  s=re.sub(r\"\\s+\", \" \", s).strip()\n",
        "  return s"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "txt = \"ÏïàÎÖïÌïòÏÑ∏Ïöî!!! üòÄ ÌÖåÏä§Ìä∏ÏûÖÎãàÎã§~ 123 üöó Hello!!\"\n",
        "print(normalize_text(txt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okDvgk7WyPOD",
        "outputId": "797759af-88e8-47b2-8aa7-0f6c57b37e28"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ÏïàÎÖïÌïòÏÑ∏Ïöî!!! ÌÖåÏä§Ìä∏ÏûÖÎãàÎã§ 123 hello!!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data=pd.read_csv('/content/ChatbotData.csv')\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "NjheArQRyR-a",
        "outputId": "94f9c6a3-a5c0-436a-f6c2-ccbaaf44341a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 Q            A  label\n",
              "0           12Ïãú Îï°!   ÌïòÎ£®Í∞Ä Îòê Í∞ÄÎÑ§Ïöî.      0\n",
              "1      1ÏßÄÎßù ÌïôÍµê Îñ®Ïñ¥Ï°åÏñ¥    ÏúÑÎ°úÌï¥ ÎìúÎ¶ΩÎãàÎã§.      0\n",
              "2     3Î∞ï4Ïùº ÎÜÄÎü¨Í∞ÄÍ≥† Ïã∂Îã§  Ïó¨ÌñâÏùÄ Ïñ∏Ï†úÎÇò Ï¢ãÏ£†.      0\n",
              "3  3Î∞ï4Ïùº Ï†ïÎèÑ ÎÜÄÎü¨Í∞ÄÍ≥† Ïã∂Îã§  Ïó¨ÌñâÏùÄ Ïñ∏Ï†úÎÇò Ï¢ãÏ£†.      0\n",
              "4          PPL Ïã¨ÌïòÎÑ§   ÎààÏÇ¥Ïù¥ Ï∞åÌë∏Î†§ÏßÄÏ£†.      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5c94b8ef-f24d-454a-9e11-e9a01bee6efc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Q</th>\n",
              "      <th>A</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12Ïãú Îï°!</td>\n",
              "      <td>ÌïòÎ£®Í∞Ä Îòê Í∞ÄÎÑ§Ïöî.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1ÏßÄÎßù ÌïôÍµê Îñ®Ïñ¥Ï°åÏñ¥</td>\n",
              "      <td>ÏúÑÎ°úÌï¥ ÎìúÎ¶ΩÎãàÎã§.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3Î∞ï4Ïùº ÎÜÄÎü¨Í∞ÄÍ≥† Ïã∂Îã§</td>\n",
              "      <td>Ïó¨ÌñâÏùÄ Ïñ∏Ï†úÎÇò Ï¢ãÏ£†.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3Î∞ï4Ïùº Ï†ïÎèÑ ÎÜÄÎü¨Í∞ÄÍ≥† Ïã∂Îã§</td>\n",
              "      <td>Ïó¨ÌñâÏùÄ Ïñ∏Ï†úÎÇò Ï¢ãÏ£†.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>PPL Ïã¨ÌïòÎÑ§</td>\n",
              "      <td>ÎààÏÇ¥Ïù¥ Ï∞åÌë∏Î†§ÏßÄÏ£†.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5c94b8ef-f24d-454a-9e11-e9a01bee6efc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5c94b8ef-f24d-454a-9e11-e9a01bee6efc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5c94b8ef-f24d-454a-9e11-e9a01bee6efc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-e0f857c6-7082-458f-81b6-d1593939fd8b\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e0f857c6-7082-458f-81b6-d1593939fd8b')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-e0f857c6-7082-458f-81b6-d1593939fd8b button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 11823,\n  \"fields\": [\n    {\n      \"column\": \"Q\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 11662,\n        \"samples\": [\n          \"\\uc0ac\\ub791\\ud558\\ub294 \\uc0ac\\ub78c \\uc78a\\ub294 \\ubc95\",\n          \"\\uc220 \\uc548 \\uba39\\uc73c\\uba74 \\uce5c\\uad6c\\ub791 \\ubb50\\ud558\\uc9c0\",\n          \"\\uc9dd\\ub0a8\\uc774 \\uace0\\uc2dc\\uc0dd\\uc774\\uba74 \\uae30\\ub2e4\\ub824\\uc57c \\ud558\\ub098\\uc694?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"A\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7779,\n        \"samples\": [\n          \"\\uc720\\uba38\\ucf54\\ub4dc\\uac00 \\ub9de\\ub294 \\uc0ac\\ub78c\\uc744 \\ucc3e\\uc544\\ubcf4\\uc138\\uc694.\",\n          \"\\uc5ec\\ud589\\uc744 \\ub5a0\\ub098 \\ubcf4\\uc138\\uc694.\",\n          \"\\ud589\\ubcf5\\ud560 \\uac70\\ub77c \\uc0dd\\uac01\\ud574\\uc694.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['Q']=data['Q'].apply(normalize_text)\n",
        "data['A']=data['A'].apply(normalize_text)\n",
        "\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Q7IWdqN7zilm",
        "outputId": "d54d2e05-f754-4d69-cd2e-8d18c19275ef"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 Q            A  label\n",
              "0           12Ïãú Îï°!   ÌïòÎ£®Í∞Ä Îòê Í∞ÄÎÑ§Ïöî.      0\n",
              "1      1ÏßÄÎßù ÌïôÍµê Îñ®Ïñ¥Ï°åÏñ¥    ÏúÑÎ°úÌï¥ ÎìúÎ¶ΩÎãàÎã§.      0\n",
              "2     3Î∞ï4Ïùº ÎÜÄÎü¨Í∞ÄÍ≥† Ïã∂Îã§  Ïó¨ÌñâÏùÄ Ïñ∏Ï†úÎÇò Ï¢ãÏ£†.      0\n",
              "3  3Î∞ï4Ïùº Ï†ïÎèÑ ÎÜÄÎü¨Í∞ÄÍ≥† Ïã∂Îã§  Ïó¨ÌñâÏùÄ Ïñ∏Ï†úÎÇò Ï¢ãÏ£†.      0\n",
              "4          ppl Ïã¨ÌïòÎÑ§   ÎààÏÇ¥Ïù¥ Ï∞åÌë∏Î†§ÏßÄÏ£†.      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f2d27d1e-d773-4a52-9288-f09180a06786\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Q</th>\n",
              "      <th>A</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12Ïãú Îï°!</td>\n",
              "      <td>ÌïòÎ£®Í∞Ä Îòê Í∞ÄÎÑ§Ïöî.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1ÏßÄÎßù ÌïôÍµê Îñ®Ïñ¥Ï°åÏñ¥</td>\n",
              "      <td>ÏúÑÎ°úÌï¥ ÎìúÎ¶ΩÎãàÎã§.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3Î∞ï4Ïùº ÎÜÄÎü¨Í∞ÄÍ≥† Ïã∂Îã§</td>\n",
              "      <td>Ïó¨ÌñâÏùÄ Ïñ∏Ï†úÎÇò Ï¢ãÏ£†.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3Î∞ï4Ïùº Ï†ïÎèÑ ÎÜÄÎü¨Í∞ÄÍ≥† Ïã∂Îã§</td>\n",
              "      <td>Ïó¨ÌñâÏùÄ Ïñ∏Ï†úÎÇò Ï¢ãÏ£†.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ppl Ïã¨ÌïòÎÑ§</td>\n",
              "      <td>ÎààÏÇ¥Ïù¥ Ï∞åÌë∏Î†§ÏßÄÏ£†.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f2d27d1e-d773-4a52-9288-f09180a06786')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f2d27d1e-d773-4a52-9288-f09180a06786 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f2d27d1e-d773-4a52-9288-f09180a06786');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-cb93d54a-f5dd-4431-8ba1-cfd1d527f5b9\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cb93d54a-f5dd-4431-8ba1-cfd1d527f5b9')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-cb93d54a-f5dd-4431-8ba1-cfd1d527f5b9 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 11823,\n  \"fields\": [\n    {\n      \"column\": \"Q\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 11659,\n        \"samples\": [\n          \"\\uc790\\uaca9\\uc99d \\uacf5\\ubd80\\ud574\\uc57c\\uc9c0\",\n          \"\\uafc8\\ub54c\\ubb38\\uc5d0 \\uc0c8\\ubcbd\\uc5d0 \\uae68\\uac8c\\ub418\\ub124.\",\n          \"\\uacb0\\ud63c\\uc740 \\ud0c0\\uc774\\ubc0d\\uc778\\uac00?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"A\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7779,\n        \"samples\": [\n          \"\\uc720\\uba38\\ucf54\\ub4dc\\uac00 \\ub9de\\ub294 \\uc0ac\\ub78c\\uc744 \\ucc3e\\uc544\\ubcf4\\uc138\\uc694.\",\n          \"\\uc5ec\\ud589\\uc744 \\ub5a0\\ub098 \\ubcf4\\uc138\\uc694.\",\n          \"\\ud589\\ubcf5\\ud560 \\uac70\\ub77c \\uc0dd\\uac01\\ud574\\uc694.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sentencepiece as spm\n",
        "\n",
        "CORPUS_TXT = \"/content/corpus_ko.txt\"\n",
        "MODEL_PREFIX = \"/content/spm_ko\"\n",
        "VOCAB_SIZE = 8000\n",
        "MODEL_TYPE = \"unigram\"\n",
        "PAD_ID, BOS_ID, EOS_ID, UNK_ID = 0, 1, 2, 3"
      ],
      "metadata": {
        "id": "3-M4krZnzzew"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_c=data[['A','Q']].fillna('').copy()\n",
        "df_c=df_c[(df_c['Q'].str.len()>0)&(df_c['A'].str.len()>0)].reset_index(drop=True)"
      ],
      "metadata": {
        "id": "H_fDrwBZ1G0B"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(CORPUS_TXT, 'w') as f:\n",
        "  for col in ['Q', 'A']:\n",
        "    for s in df_c[col].astype(str):\n",
        "      if s.strip():\n",
        "        f. write(s.strip()+\"\\n\")"
      ],
      "metadata": {
        "id": "Sg6bHAgN1sfs"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spm.SentencePieceTrainer.Train(input=CORPUS_TXT,\n",
        "    model_prefix=MODEL_PREFIX,\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    character_coverage=1.0,\n",
        "    model_type=MODEL_TYPE,\n",
        "    pad_id=0, bos_id=1, eos_id=2, unk_id=3,\n",
        "    max_sentence_length=999999)"
      ],
      "metadata": {
        "id": "Ax0wBQj02yog"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sp = spm.SentencePieceProcessor()\n",
        "sp.load(f\"{MODEL_PREFIX}.model\")\n",
        "print(\"ids: pad/bos/eos/unk =\", sp.pad_id(), sp.bos_id(), sp.eos_id(), sp.unk_id())\n",
        "\n",
        "sample = df_c[\"Q\"].iloc[0]\n",
        "print(\"sample:\", sample)\n",
        "print(\"pieces:\", sp.encode(sample, out_type=str))\n",
        "print(\"ids   :\", sp.encode(sample, out_type=int))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t42v2l3l3b-l",
        "outputId": "75d6f89e-8ac6-4291-8672-074d1fb4347c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ids: pad/bos/eos/unk = 0 1 2 3\n",
            "sample: 12Ïãú Îï°!\n",
            "pieces: ['‚ñÅ12', 'Ïãú', '‚ñÅ', 'Îï°', '!']\n",
            "ids   : [4275, 549, 5, 7825, 64]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "PAD, BOS, EOS= sp.pad_id(), sp.bos_id(), sp.eos_id()\n",
        "MAX_LEN=40\n",
        "\n",
        "def encode_with_bos_eos(text):\n",
        "  ids=sp.encode(str(text), out_type=int)\n",
        "  return [BOS]+ids+[EOS]\n",
        "\n",
        "class KoChatDataset(Dataset):\n",
        "  def __init__(self,df,max_len=MAX_LEN):\n",
        "    self.items=[]\n",
        "    for q,a in zip(df_c['Q'], df_c['A']):\n",
        "      q_ids=encode_with_bos_eos(q)\n",
        "      a_ids=encode_with_bos_eos(a)\n",
        "      if len(q_ids)>max_len or len(a_ids)>max_len:\n",
        "        continue\n",
        "\n",
        "      q_ids=q_ids+[PAD]*(max_len-len(q_ids))\n",
        "      a_ids=a_ids+[PAD]*(max_len-len(a_ids))\n",
        "\n",
        "      dec_in=a_ids[:-1]\n",
        "      target=a_ids[1:]\n",
        "      self.items.append((\n",
        "          torch.tensor(q_ids,dtype=torch.long),\n",
        "          torch.tensor(dec_in,dtype=torch.long),\n",
        "          torch.tensor(target, dtype=torch.long)\n",
        "      ))\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.items)\n",
        "\n",
        "  def __getitem__(self,i):\n",
        "    return self.items[i]\n",
        ""
      ],
      "metadata": {
        "id": "bzFnCJEG3wfB"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import random_split\n",
        "full_ds=KoChatDataset(df_c)\n",
        "n_total=len(full_ds)\n",
        "n_val=int(0.1*n_total)\n",
        "n_train=n_total-n_val\n",
        "\n",
        "train_ds,val_ds=random_split(full_ds,[n_train,n_val])\n",
        "train_dl=DataLoader(train_ds,batch_size=64,shuffle=True, drop_last=True)\n",
        "val_dl=DataLoader(val_ds,batch_size=64,shuffle=False)"
      ],
      "metadata": {
        "id": "Bla8kcOP35k0"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Î™®Îç∏ ÏÑ§Í≥Ñ"
      ],
      "metadata": {
        "id": "7tbU6uud2-Mx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from typing import Optional\n",
        "\n",
        "def create_padding_mask(x,pad_id):\n",
        "  mask=(x==pad_id).float()\n",
        "  return mask.unsqueeze(1).unsqueeze(2)\n",
        "\n",
        "def create_look_ahead_mask(tgt_len,device=None):\n",
        "  m=torch.triu(torch.ones(tgt_len, tgt_len, device=device), diagonal=1)\n",
        "  m=m.unsqueeze(0).unsqueeze(0)\n",
        "  return m\n",
        "\n",
        "def combine_masks(causal,pad):\n",
        "  if causal is None:\n",
        "    return pad\n",
        "  if pad is None:\n",
        "    return causal\n",
        "  return torch.max(causal,pad)\n",
        "\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model: int, max_len: int = 512):\n",
        "        super().__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        pos = torch.arange(0, max_len).unsqueeze(1).float()\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(pos * div_term)\n",
        "        pe[:, 1::2] = torch.cos(pos * div_term)\n",
        "        self.register_buffer(\"pe\", pe.unsqueeze(0))  # (1, max_len, d_model)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        # x: (B,L,D)\n",
        "        return x + self.pe[:, : x.size(1), :]\n",
        "\n",
        "\n",
        "def scaled_dot_product_attention(Q,K,V,mask=None):\n",
        "  dk=K.size(-1)\n",
        "  scores=torch.matmul(Q,K.transpose(-1,-2))/math.sqrt(dk)\n",
        "  if mask is not None:\n",
        "    scores=scores+(mask*(-1e9))\n",
        "  attn=F.softmax(scores,dim=-1)\n",
        "  out=torch.matmul(attn,V)\n",
        "  return out,attn\n",
        "\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "  def __init__(self,d_model,num_heads,dropout=0.1):\n",
        "    super().__init__()\n",
        "    self.num_heads=num_heads\n",
        "    self.d_model=d_model\n",
        "    self.depth=d_model//num_heads\n",
        "\n",
        "    self.Wq=nn.Linear(d_model,d_model)\n",
        "    self.Wk=nn.Linear(d_model,d_model)\n",
        "    self.Wv=nn.Linear(d_model,d_model)\n",
        "    self.Wo=nn.Linear(d_model,d_model)\n",
        "    self.drop=nn.Dropout(dropout)\n",
        "\n",
        "  def split_heads(self,x):\n",
        "    B,L,D=x.shape\n",
        "    x=x.view(B,L,self.num_heads, self.depth)\n",
        "    return x.permute(0,2,1,3)\n",
        "\n",
        "  def combine_heads(self,x):\n",
        "    B,H,L,d=x.shape\n",
        "    x=x.permute(0,2,1,3).contiguous()\n",
        "    return x.view(B,L,H*d)\n",
        "\n",
        "  def forward(self,q,k,v,mask=None):\n",
        "    Q=self.split_heads(self.Wq(q))\n",
        "    K=self.split_heads(self.Wk(k))\n",
        "    V=self.split_heads(self.Wv(v))\n",
        "    if mask is not None and mask.dim() == 4:\n",
        "            pass\n",
        "    out, attn = scaled_dot_product_attention(Q, K, V, mask)\n",
        "    out = self.combine_heads(self.drop(out))\n",
        "    return self.Wo(out)\n",
        "\n",
        "\n",
        "class PositionwiseFFN(nn.Module):\n",
        "    def __init__(self, d_model, ff_dim, dropout= 0.1):\n",
        "        super().__init__()\n",
        "        self.lin1 = nn.Linear(d_model, ff_dim)\n",
        "        self.lin2 = nn.Linear(ff_dim, d_model)\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.lin2(self.drop(F.relu(self.lin1(x))))\n",
        "\n",
        "\n",
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, ff_dim, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.mha = MultiHeadAttention(d_model, num_heads, dropout)\n",
        "        self.ffn = PositionwiseFFN(d_model, ff_dim, dropout)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, src_mask= None):\n",
        "        attn_out = self.mha(x, x, x, src_mask)\n",
        "        x = self.norm1(x + self.drop(attn_out))\n",
        "        ffn_out = self.ffn(x)\n",
        "        x = self.norm2(x + self.drop(ffn_out))\n",
        "        return x\n",
        "\n",
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, ff_dim, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.self_mha = MultiHeadAttention(d_model, num_heads, dropout)\n",
        "        self.cross_mha = MultiHeadAttention(d_model, num_heads, dropout)\n",
        "        self.ffn = PositionwiseFFN(d_model, ff_dim, dropout)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.norm3 = nn.LayerNorm(d_model)\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, enc_out, tgt_mask= None, cross_mask = None):\n",
        "        _x = self.self_mha(x, x, x, tgt_mask)\n",
        "        x = self.norm1(x + self.drop(_x))\n",
        "        _x = self.cross_mha(x, enc_out, enc_out, cross_mask)\n",
        "        x = self.norm2(x + self.drop(_x))\n",
        "        _x = self.ffn(x)\n",
        "        x = self.norm3(x + self.drop(_x))\n",
        "        return x\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model, num_layers, num_heads, ff_dim, pad_id, dropout=0.1, max_len=512):\n",
        "        super().__init__()\n",
        "        self.pad = pad_id\n",
        "        self.emb = nn.Embedding(vocab_size, d_model, padding_idx=pad_id)\n",
        "        self.pos = PositionalEncoding(d_model, max_len)\n",
        "        self.layers = nn.ModuleList([\n",
        "            DecoderLayer(d_model, num_heads, ff_dim, dropout) for _ in range(num_layers)\n",
        "        ])\n",
        "\n",
        "    def forward(self, tgt, enc_out, src_mask):\n",
        "        x = self.pos(self.emb(tgt))\n",
        "        B, Lt = tgt.size()\n",
        "        causal = create_look_ahead_mask(Lt, device=tgt.device)\n",
        "        padmask_tgt = create_padding_mask(tgt, self.pad)\n",
        "        tgt_mask = combine_masks(causal, padmask_tgt)\n",
        "        cross_mask = src_mask\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, enc_out, tgt_mask, cross_mask)\n",
        "        return x\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model, num_layers, num_heads, ff_dim, pad_id, dropout=0.1, max_len=512):\n",
        "        super().__init__()\n",
        "        self.pad = pad_id\n",
        "        self.emb = nn.Embedding(vocab_size, d_model, padding_idx=pad_id)\n",
        "        self.pos = PositionalEncoding(d_model, max_len)\n",
        "        self.layers = nn.ModuleList([\n",
        "            EncoderLayer(d_model, num_heads, ff_dim, dropout) for _ in range(num_layers)\n",
        "        ])\n",
        "\n",
        "    def forward(self, src):\n",
        "        x = self.pos(self.emb(src))\n",
        "        src_mask = create_padding_mask(src, self.pad)\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, src_mask)\n",
        "        return x, src_mask\n",
        "\n",
        "class TransformerSeq2Seq(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model, num_layers, num_heads, ff_dim, pad_id, dropout=0.1, max_len=512):\n",
        "        super().__init__()\n",
        "        self.encoder = Encoder(vocab_size, d_model, num_layers, num_heads, ff_dim, pad_id, dropout, max_len)\n",
        "        self.decoder = Decoder(vocab_size, d_model, num_layers, num_heads, ff_dim, pad_id, dropout, max_len)\n",
        "        self.out = nn.Linear(d_model, vocab_size)\n",
        "        self.pad = pad_id\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        enc_out, src_mask = self.encoder(src)\n",
        "        dec_out = self.decoder(tgt, enc_out, src_mask)\n",
        "        logits = self.out(dec_out)\n",
        "        return logits\n",
        "\n",
        "class TransformerWarmupLR(torch.optim.lr_scheduler.LambdaLR):\n",
        "  def __init__(self, optimizer, d_model, warmup_steps=4000):\n",
        "    def lr_lambda(step):\n",
        "      step=step+1\n",
        "      return (d_model ** -0.5) * min(step ** -0.5, step * (warmup_steps ** -1.5))\n",
        "    super().__init__(optimizer, lr_lambda=lr_lambda)\n",
        "\n",
        "def train_step(model,batch,optimizer,loss_fn,device):\n",
        "  model.train()\n",
        "  src,tgt_in,tgt_out=[x.to(device) for x in batch]\n",
        "  optimizer.zero_grad()\n",
        "  logits=model(src,tgt_in)\n",
        "  B,L,V=logits.shape\n",
        "  loss=loss_fn(logits.reshape(B*L,V), tgt_out.reshape(B*L))\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  with torch.no_grad():\n",
        "    preds=logits.argmax(-1)\n",
        "    mask=(tgt_out!=model.pad)\n",
        "    acc=(preds.eq(tgt_out) & mask).float().sum()/mask.float().sum()\n",
        "  return loss.item(), acc.item()"
      ],
      "metadata": {
        "id": "wm5O55pOJFx4"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 8000\n",
        "d_model    = 192\n",
        "n_layers   = 3\n",
        "n_heads    = 6\n",
        "ff_dim     = 768\n",
        "pad_id     = 0\n",
        "max_len    = 40\n"
      ],
      "metadata": {
        "id": "MeNC9aJPWTVk"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model=TransformerSeq2Seq(vocab_size, d_model, n_layers, n_heads, ff_dim, pad_id, 0.1, max_len).to(device)\n",
        "optimizer=torch.optim.Adam(model.parameters(), lr=1.0, betas=(0.9, 0.98), eps=1e-9)\n",
        "scheduler=TransformerWarmupLR(optimizer, d_model, warmup_steps=4000)\n",
        "loss_fn=nn.CrossEntropyLoss(ignore_index=pad_id).to(device)"
      ],
      "metadata": {
        "id": "4ithjtaCWaq8"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE   = 64\n",
        "EPOCHS       = 5\n",
        "MAX_LEN      = 40\n",
        "LR           = 1.0\n",
        "CLIP_NORM    = 1.0\n",
        "VAL_FRACTION = 0.1\n",
        "VOCAB_SIZE = 8000\n",
        "\n",
        "@torch.no_grad()\n",
        "def validate():\n",
        "  model.eval()\n",
        "  total_loss, total_acc, n_batches=0,0,0\n",
        "  for batch in val_dl:\n",
        "    src,dec_in,tgt=[x.to(device) for x in batch]\n",
        "    logits=model(src,dec_in)\n",
        "    B,L,V=logits.shape\n",
        "    loss=loss_fn(logits.reshape(B*L,V), tgt.reshape(B*L))\n",
        "    preds=logits.argmax(-1)\n",
        "    mask=(tgt!=PAD)\n",
        "    acc = (preds.eq(tgt) & mask).float().sum() / mask.float().sum()\n",
        "    total_loss += loss.item()\n",
        "    total_acc  += acc.item()\n",
        "    n_batches  += 1\n",
        "  return total_loss / max(1,n_batches), total_acc / max(1,n_batches)\n"
      ],
      "metadata": {
        "id": "qioL1SMcXda6"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ÌïôÏäµ"
      ],
      "metadata": {
        "id": "p9C6GYQN3EF8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "for epoch in range(1, 20):\n",
        "  model.train()\n",
        "  epoch_loss, epoch_acc, n_batches=0,0,0\n",
        "  t0=time.time()\n",
        "  for batch in train_dl:\n",
        "    loss, acc=train_step(model,batch,optimizer,loss_fn, device)\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), CLIP_NORM)\n",
        "    scheduler.step()\n",
        "    epoch_loss += loss\n",
        "    epoch_acc  += acc\n",
        "    n_batches  += 1\n",
        "  train_loss = epoch_loss / max(1,n_batches)\n",
        "  train_acc  = epoch_acc  / max(1,n_batches)\n",
        "\n",
        "  val_loss, val_acc = validate()\n",
        "  dt = time.time() - t0\n",
        "  print(f\"[{epoch:02d}] {dt:.1f}s  train loss {train_loss:.4f} acc {train_acc:.4f} | \"\n",
        "          f\"val loss {val_loss:.4f} acc {val_acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGwyqhg0bqja",
        "outputId": "6dd7321e-3c1f-4c53-a075-82d1220f0172"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[01] 6.4s  train loss 4.2883 acc 0.3625 | val loss 4.4016 acc 0.3704\n",
            "[02] 6.3s  train loss 3.9754 acc 0.3874 | val loss 4.2126 acc 0.3901\n",
            "[03] 6.4s  train loss 3.6749 acc 0.4141 | val loss 4.0478 acc 0.4033\n",
            "[04] 6.3s  train loss 3.3698 acc 0.4425 | val loss 3.9035 acc 0.4209\n",
            "[05] 6.6s  train loss 3.0609 acc 0.4768 | val loss 3.7798 acc 0.4329\n",
            "[06] 6.3s  train loss 2.7283 acc 0.5168 | val loss 3.6582 acc 0.4524\n",
            "[07] 6.8s  train loss 2.3887 acc 0.5627 | val loss 3.6086 acc 0.4629\n",
            "[08] 6.3s  train loss 2.0515 acc 0.6135 | val loss 3.5134 acc 0.4790\n",
            "[09] 6.4s  train loss 1.7197 acc 0.6657 | val loss 3.4615 acc 0.4924\n",
            "[10] 6.4s  train loss 1.4046 acc 0.7187 | val loss 3.4696 acc 0.5055\n",
            "[11] 6.4s  train loss 1.1300 acc 0.7674 | val loss 3.4795 acc 0.5172\n",
            "[12] 6.5s  train loss 0.8928 acc 0.8116 | val loss 3.5505 acc 0.5253\n",
            "[13] 6.4s  train loss 0.7133 acc 0.8428 | val loss 3.6209 acc 0.5317\n",
            "[14] 6.5s  train loss 0.5772 acc 0.8702 | val loss 3.6973 acc 0.5403\n",
            "[15] 6.4s  train loss 0.4840 acc 0.8889 | val loss 3.8042 acc 0.5429\n",
            "[16] 6.6s  train loss 0.4280 acc 0.8970 | val loss 3.8948 acc 0.5443\n",
            "[17] 6.4s  train loss 0.4004 acc 0.9007 | val loss 3.9892 acc 0.5493\n",
            "[18] 6.5s  train loss 0.3883 acc 0.9010 | val loss 4.0663 acc 0.5495\n",
            "[19] 6.5s  train loss 0.3751 acc 0.9047 | val loss 4.1704 acc 0.5445\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ÌÖåÏä§Ìä∏"
      ],
      "metadata": {
        "id": "FJekjQH_3HoD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def decoder_inference(model, sentence, tokenizer, device='cpu', max_length=40,start_token=None, end_token=None):\n",
        "  START_TOKEN=start_token if start_token is not None else tokenizer.bos_id()\n",
        "  END_TOKEN=end_token if end_token is not None else tokenizer.eos_id()\n",
        "  sentence=normalize_text(sentence)\n",
        "\n",
        "  enc_input_ids=[START_TOKEN]+tokenizer.encode(sentence)+[END_TOKEN]\n",
        "  enc_input=torch.tensor([enc_input_ids], dtype=torch.long, device=device)\n",
        "\n",
        "  dec_input=torch.tensor([[START_TOKEN]], dtype=torch.long, device=device)\n",
        "\n",
        "  model.eval()\n",
        "  generated_tokens=[]\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for _ in range(max_length):\n",
        "      logits=model(enc_input, dec_input)\n",
        "      last_step_logits=logits[:,-1,:]\n",
        "      predicted_id=torch.argmax(last_step_logits, dim=-1)\n",
        "      token_id=predicted_id.item()\n",
        "      if token_id==END_TOKEN:\n",
        "        break\n",
        "      generated_tokens.append(token_id)\n",
        "      dec_input=torch.cat([dec_input,predicted_id.unsqueeze(0)], dim=1)\n",
        "  output_sequence=[START_TOKEN]+generated_tokens\n",
        "  return output_sequence, tokenizer.decode(generated_tokens)"
      ],
      "metadata": {
        "id": "ud6an_pnxfnY"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_inference(example):\n",
        "  tokens, decoded=decoder_inference(model, example, sp, device=device)\n",
        "  print(f'question: {example}')\n",
        "  print(f'answer: {decoded}')\n"
      ],
      "metadata": {
        "id": "55wPaiRR01_g"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_inference('ÏïàÎÖï!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czRuAIC_1gkO",
        "outputId": "cc489898-6e85-4774-eb34-3404bc40a2c0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "question: ÏïàÎÖï!\n",
            "answer: ÏïàÎÖïÌïòÏÑ∏Ïöî.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_inference('Î≠ê ÌïòÍ≥† ÏûàÏñ¥Ïöî?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPwYIayP1laK",
        "outputId": "ed7bde50-d5c6-4d02-bda4-23c6e409ea17"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "question: Î≠ê ÌïòÍ≥† ÏûàÏñ¥Ïöî?\n",
            "answer: Ï†ÄÎäî ÏúÑÎ°úÎ¥áÏù¥Ïöî.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_inference('Ïò§Îäò ÎÇ†Ïî®Í∞Ä Ïñ¥ÎïåÏöî?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "163cHQyj1wQO",
        "outputId": "c49a2132-f6a2-4de4-f4e8-30ae68f7f939"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "question: Ïò§Îäò ÎÇ†Ïî®Í∞Ä Ïñ¥ÎïåÏöî?\n",
            "answer: Ïò§ÎäòÏùÄ ÏòàÎä•Ïù¥Ïöî.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_inference('ÎÑà ÎàÑÍµ¨ÏòàÏöî?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypFFr4lX2Qxy",
        "outputId": "0e8970c5-0d84-4a08-b2be-5f95628b0b81"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "question: ÎÑà ÎàÑÍµ¨ÏòàÏöî?\n",
            "answer: Ï†ÄÎèÑ Í∂ÅÍ∏àÌïòÎÑ§Ïöî.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_inference('ÏÇ¨ÎûåÎì§ Ïôú ÏÇ¥ÏïÑÏöî?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GamE83Sb43QK",
        "outputId": "22b3a3a3-bf2a-49db-b95e-0efa224f7996"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "question: ÏÇ¨ÎûåÎì§ Ïôú ÏÇ¥ÏïÑÏöî?\n",
            "answer: Í∑∏Î†áÍ≤å ÎßåÎì§ÏóàÎÇòÏöî.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Í≤∞Í≥º:\n",
        "\n",
        "**ÌïúÍµ≠Ïñ¥ Ï†ÑÏ≤òÎ¶¨.**\n",
        "\n",
        "normalize_text:\n",
        "ÏÜåÎ¨∏ÏûêÌôî, Ï†ïÍ∑úÏãùÏúºÎ°ú ÌïúÍ∏Ä/ÏòÅÎ¨∏/Ïà´Ïûê/Í∏∞Î≥∏ Î¨∏Ïû•Î∂ÄÌò∏(.,?!) Îßå Ïú†ÏßÄ, Í≥µÎ∞± Ï†ïÎ¶¨.\n",
        "\n",
        "Ï†ïÏ†úÎêú Q/AÎ°ú ÏΩîÌçºÏä§ ÌååÏùº ÏÉùÏÑ±.\n",
        "\n",
        "SentencePiece(UNigram, vocab=8000, coverage=1.0) ÌïôÏäµ, Ïä§ÌéòÏÖú ÌÜ†ÌÅ∞ ID Í≥†Ï†ï:\n",
        "PAD=0, BOS=1, EOS=2, UNK=3.\n",
        "\n",
        "Teacher Forcing Îç∞Ïù¥ÌÑ∞ Íµ¨ÏÑ±:\n",
        "\n",
        "Ïù∏ÏΩîÎçî ÏûÖÎ†•: [BOS] + encode(Q) + [EOS] (Ìå®Îî©),\n",
        "\n",
        "ÎîîÏΩîÎçî: dec_input=a[:-1], target=a[1:].\n",
        "\n",
        "**Î™®Îç∏.**\n",
        "\n",
        "ÏÇ¨Ïù∏/ÏΩîÏÇ¨Ïù∏ Positional Encoding,\n",
        "\n",
        "Multi-Head Attention(Q/K/V/Out = Linear(d_model, d_model)), Ìó§Îìú Î∂ÑÌï†/Í≤∞Ìï©,\n",
        "\n",
        "EncoderLayer/DecoderLayer + Residual/LayerNorm, FFN(ReLU, Dropout),\n",
        "\n",
        "ÎßàÏä§ÌÅ¨: Ìå®Îî© ÎßàÏä§ÌÅ¨ (B,1,1,L), look-ahead ÏÉÅÏÇºÍ∞Å ÎßàÏä§ÌÅ¨ (1,1,L,L).\n",
        "\n",
        "**ÌïôÏäµ.**\n",
        "\n",
        "ÏÜêÏã§: CrossEntropyLoss(ignore_index=PAD),\n",
        "\n",
        "ÏßÄÌëú: PAD Ï†úÏô∏ ÌÜ†ÌÅ∞ Ï†ïÌôïÎèÑ,\n",
        "\n",
        "Í≤ÄÏ¶ù: random_split(Í≤ÄÏ¶ù 10%),\n",
        "\n",
        "Warmup LR Ïä§ÏºÄÏ§ÑÎü¨(Transformer Î∞©Ïãù, warmup_steps=4000),\n",
        "\n",
        "Gradient Clipping(clip_grad_norm_(‚Ä¶, 1.0)),\n",
        "\n",
        "ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞ ÏòàÏãú: d_model=192, heads=6, ff=768, layers=3, MAX_LEN=40, batch=64.\n",
        "\n",
        "**ÌõàÎ†® Í≥ºÏ†ïÏóêÏÑú ÌïôÏäµ Îç∞Ïù¥ÌÑ∞Ïùò ÏÜêÏã§ÏùÄ Íæ∏Ï§ÄÌûà Í∞êÏÜåÌïòÍ≥† Ï†ïÌôïÎèÑÎäî 0.36ÏóêÏÑú 0.90 Ïù¥ÏÉÅÍπåÏßÄ ÏÉÅÏäπÌñàÏäµÎãàÎã§. Í≤ÄÏ¶ù Îç∞Ïù¥ÌÑ∞ÏóêÏÑúÎèÑ ÏÑ±Îä•Ïù¥ Í∞úÏÑ†ÎêòÏóàÏßÄÎßå, ÏïΩ 12~13 ÏóêÌè¨ÌÅ¨ Ïù¥ÌõÑÎ∂ÄÌÑ∞Îäî Í≥ºÏ†ÅÌï© ÌòÑÏÉÅÏù¥ ÎÇòÌÉÄÎÇòÎ©¥ÏÑú train lossÎäî Í≥ÑÏÜç Ï§ÑÏñ¥ÎìúÎäî Î∞òÎ©¥ val lossÎäî Ï†êÏ∞® Ï¶ùÍ∞ÄÌñàÏäµÎãàÎã§. Í∑∏ÎüºÏóêÎèÑ Î∂àÍµ¨ÌïòÍ≥† Î™®Îç∏ÏùÄ Í∞ÑÎã®Ìïú ÏßàÎ¨∏ÏóêÎäî ÎåÄÎãµÌï† Ïàò ÏûàÎäî ÏàòÏ§ÄÏóê ÎèÑÎã¨ÌïòÏó¨ Í∏∞Î≥∏Ï†ÅÏù∏ ÎåÄÌôîÌòï Ï±óÎ¥áÏúºÎ°ú ÌôúÏö© Í∞ÄÎä•Ìï©ÎãàÎã§**.\n",
        "\n",
        "Greedy decoding: [BOS]Î°ú ÏãúÏûë, ÎßàÏßÄÎßâ Î°úÏßì argmax Î∞òÎ≥µ, [EOS] ÎòêÎäî ÏµúÎåÄ Í∏∏Ïù¥ÏóêÏÑú Ï§ëÎã®.\n"
      ],
      "metadata": {
        "id": "OScMdEF84XUJ"
      }
    }
  ]
}