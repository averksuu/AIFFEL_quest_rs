{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac209c43",
   "metadata": {
    "id": "u_7tQLSfDo8a"
   },
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    import peft  # noqa: F401\n",
    "except ImportError:\n",
    "    %pip -q install peft accelerate transformers datasets sentencepiece\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80e6ea1",
   "metadata": {
    "id": "eZZF_hNOzxi8"
   },
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "cfg = LoraConfig(\n",
    "    r=16, lora_alpha=32, lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"SEQ_CLS\",          # <-- ВАЖНО: не CAUSAL_LM\n",
    "    target_modules=[\"c_attn\",\"c_proj\",\"c_fc\",\"q_proj\",\"k_proj\",\"v_proj\",\"o_proj\",\"gate_proj\",\"up_proj\",\"down_proj\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafd2f07",
   "metadata": {
    "id": "Z8UHHVgrDo8b"
   },
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "except NameError:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f645d83",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x0cFwdXDh1eV",
    "outputId": "d1430d97-36d1-496a-8c3a-23d0b97eaf86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.19.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.34.4)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.15)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.9)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2025.8.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Collecting loralib\n",
      "  Downloading loralib-0.1.2-py3-none-any.whl.metadata (15 kB)\n",
      "Downloading loralib-0.1.2-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: loralib\n",
      "Successfully installed loralib-0.1.2\n",
      "Collecting trl\n",
      "  Downloading trl-0.23.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: accelerate>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from trl) (1.10.1)\n",
      "Requirement already satisfied: datasets>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from trl) (4.0.0)\n",
      "Requirement already satisfied: transformers>=4.56.1 in /usr/local/lib/python3.12/dist-packages (from trl) (4.56.1)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.12/dist-packages (from accelerate>=1.4.0->trl) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from accelerate>=1.4.0->trl) (25.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate>=1.4.0->trl) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate>=1.4.0->trl) (6.0.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate>=1.4.0->trl) (2.8.0+cu126)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from accelerate>=1.4.0->trl) (0.34.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate>=1.4.0->trl) (0.6.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl) (3.19.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (2025.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.56.1->trl) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.56.1->trl) (0.22.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (3.12.15)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate>=1.4.0->trl) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate>=1.4.0->trl) (1.1.9)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (2025.8.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (3.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets>=3.0.0->trl) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets>=3.0.0->trl) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets>=3.0.0->trl) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (1.20.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=3.0.0->trl) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate>=1.4.0->trl) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate>=1.4.0->trl) (3.0.2)\n",
      "Downloading trl-0.23.0-py3-none-any.whl (564 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m564.7/564.7 kB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: trl\n",
      "Successfully installed trl-0.23.0\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.10.1)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (25.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate) (6.0.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.8.0+cu126)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (0.34.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate) (0.6.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (3.19.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2025.3.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (1.1.9)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.4.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2025.8.3)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.56.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.34.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.9)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.8.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets\n",
    "!pip install loralib\n",
    "!pip install trl\n",
    "!pip install accelerate\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcbe385",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NLMBK-sHh2z2",
    "outputId": "1a1ad420-b204-47e3-c615-14d7ed898855"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'KoChatGPT'...\n",
      "remote: Enumerating objects: 304, done.\u001b[K\n",
      "remote: Total 304 (delta 0), reused 0 (delta 0), pack-reused 304 (from 1)\u001b[K\n",
      "Receiving objects: 100% (304/304), 57.72 MiB | 11.38 MiB/s, done.\n",
      "Resolving deltas: 100% (123/123), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/airobotlab/KoChatGPT\n",
    "!cp -r KoChatGPT/colossalai_ChatGPT_230319/chatgpt chatgpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903cc882",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oBk3Q8aCh8Du",
    "outputId": "e3c2dc42-c2d4-40cc-e745-7c437096f53f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 수정 완료: chatgpt/trainer/callbacks/save_checkpoint.py\n",
      "✅ 수정 완료: chatgpt/trainer/strategies/__init__.py\n",
      "✅ 수정 완료: chatgpt/dataset/reward_dataset.py\n",
      "⚠️ chatgpt/trainer/strategies/__init__.py 수정할 내용이 없습니다.\n",
      "⚠️ chatgpt/dataset/reward_dataset.py 파일의 8번째 줄이 예상과 다릅니다.\n",
      "   예상: from tqdm import tqdm\n",
      "   실제: class RewardDataset(Dataset):\n",
      "⚠️ chatgpt/dataset/reward_dataset.py 수정할 내용이 없습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "modifications = [\n",
    "    {\n",
    "        \"file\": \"chatgpt/trainer/callbacks/save_checkpoint.py\",\n",
    "        \"changes\": [\n",
    "            {\"line\": 3, \"old\": \"from chatgpt.trainer.strategies import ColossalAIStrategy, Strategy\",\n",
    "             \"new\": \"from chatgpt.trainer.strategies import Strategy\"},\n",
    "            {\"line\": 71, \"old\": \"only_rank0 = not isinstance(self.strategy, ColossalAIStrategy)\",\n",
    "             \"new\": \"            only_rank0 = not isinstance(self.strategy)\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"file\": \"chatgpt/trainer/strategies/__init__.py\",\n",
    "        \"changes\": [\n",
    "            {\"line\": 1, \"old\": \"from .colossalai import ColossalAIStrategy\", \"new\": \"\"},  # 삭제\n",
    "            {\"line\": 5, \"old\": \"__all__ = ['Strategy', 'NaiveStrategy', 'DDPStrategy', 'ColossalAIStrategy']\",\n",
    "             \"new\": \"__all__ = ['Strategy', 'NaiveStrategy', 'DDPStrategy']\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"file\": \"chatgpt/dataset/reward_dataset.py\",\n",
    "        \"changes\": [\n",
    "            {\"line\": 3, \"old\": \"from tqdm import tqdm\", \"new\": \"from tqdm.notebook import tqdm\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"file\": \"chatgpt/trainer/strategies/__init__.py\",\n",
    "        \"changes\": [\n",
    "            {\"line\": 8, \"old\": \"from tqdm import tqdm\", \"new\": \"from tqdm.notebook import tqdm\"},\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"file\": \"chatgpt/dataset/reward_dataset.py\",\n",
    "        \"changes\": [\n",
    "            {\"line\": 8, \"old\": \"from tqdm import tqdm\", \"new\": \"from tqdm.notebook import tqdm\"},\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "def modify_file(file_path, changes):\n",
    "    \"\"\"파일에서 지정된 줄을 찾아 내용을 수정하는 함수\"\"\"\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"⚠️ 파일이 존재하지 않습니다: {file_path}\")\n",
    "        return\n",
    "\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    modified = False\n",
    "\n",
    "    for change in changes:\n",
    "        line_index = change[\"line\"]\n",
    "        if 0 <= line_index < len(lines):\n",
    "            if lines[line_index].strip() == change[\"old\"]:\n",
    "                lines[line_index] = change[\"new\"] + \"\\n\"\n",
    "                modified = True\n",
    "            else:\n",
    "                print(f\"⚠️ {file_path} 파일의 {change['line']}번째 줄이 예상과 다릅니다.\")\n",
    "                print(f\"   예상: {change['old']}\")\n",
    "                print(f\"   실제: {lines[line_index].strip()}\")\n",
    "\n",
    "    if modified:\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.writelines(lines)\n",
    "        print(f\"✅ 수정 완료: {file_path}\")\n",
    "    else:\n",
    "        print(f\"⚠️ {file_path} 수정할 내용이 없습니다.\")\n",
    "\n",
    "for mod in modifications:\n",
    "    modify_file(mod[\"file\"], mod[\"changes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd903d76",
   "metadata": {
    "id": "UlruUmphh-qN"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import pandas as pd\n",
    "import numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750fed6b",
   "metadata": {
    "id": "88CNKB-WgV7s"
   },
   "outputs": [],
   "source": [
    "import json, random\n",
    "from datasets import Dataset\n",
    "\n",
    "data_path = 'KoChatGPT/data_kochatgpt/kochatgpt_2_RM.jsonl'\n",
    "with open(data_path, 'r', encoding='utf-8-sig') as f:\n",
    "    triplets = json.load(f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58f784d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H_G1cvmfiTJF",
    "outputId": "eda76c3a-9d60-43dc-fd12-cd0ba12e1822"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 26907 eval: 2990\n"
     ]
    }
   ],
   "source": [
    "def triplet_to_pairs(ex):\n",
    "    pairs = []\n",
    "    comps = [ex['completion_0'], ex['completion_1'], ex['completion_2']]\n",
    "    ranks = ex['ranking']\n",
    "    idx = [0,1,2]\n",
    "    for a in range(3):\n",
    "        for b in range(a+1,3):\n",
    "            i,j = idx[a], idx[b]\n",
    "            if ranks[i] < ranks[j]:\n",
    "                chosen, rejected = comps[i], comps[j]\n",
    "            else:\n",
    "                chosen, rejected = comps[j], comps[i]\n",
    "            pairs.append({\n",
    "                \"prompt\": ex[\"prompt\"],\n",
    "                \"chosen\": chosen,\n",
    "                \"rejected\": rejected\n",
    "            })\n",
    "    return pairs\n",
    "\n",
    "pairs = []\n",
    "for ex in triplets:\n",
    "    pairs.extend(triplet_to_pairs(ex))\n",
    "\n",
    "def ok(s): return isinstance(s,str) and len(s.strip())>3\n",
    "pairs = [p for p in pairs if ok(p[\"prompt\"]) and ok(p[\"chosen\"]) and ok(p[\"rejected\"])]\n",
    "\n",
    "\n",
    "random.seed(42)\n",
    "random.shuffle(pairs)\n",
    "split = int(0.9*len(pairs))\n",
    "train_data = pairs[:split]\n",
    "eval_data  = pairs[split:]\n",
    "\n",
    "print(\"train:\", len(train_data), \"eval:\", len(eval_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39d047a",
   "metadata": {
    "id": "A-HaLqsdjU9G"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "INSTR = \"### Instruction:\\n\"\n",
    "RESP  = \"\\n\\n### Response:\\n\"\n",
    "\n",
    "base_id = \"skt/kogpt2-base-v2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    base_id,\n",
    "    bos_token=\"</s>\", eos_token=\"</s>\", unk_token=\"</s>\", pad_token=\"</s>\",\n",
    "    padding_side=\"right\", model_max_length=512\n",
    ")\n",
    "\n",
    "def format_sample(prompt, completion):\n",
    "    text = f\"{INSTR}{prompt}{RESP}{completion}{tokenizer.eos_token}\"\n",
    "    return text\n",
    "\n",
    "class RMPairsDataset:\n",
    "    def __init__(self, data, tokenizer, max_len=512):\n",
    "        self.data = data\n",
    "        self.tok = tokenizer\n",
    "        self.max_len = max_len\n",
    "    def __len__(self): return len(self.data)\n",
    "    def __getitem__(self, i):\n",
    "        ex = self.data[i]\n",
    "        return {\n",
    "            \"chosen_text\":   format_sample(ex[\"prompt\"], ex[\"chosen\"]),\n",
    "            \"rejected_text\": format_sample(ex[\"prompt\"], ex[\"rejected\"])\n",
    "        }\n",
    "\n",
    "train_ds = RMPairsDataset(train_data, tokenizer)\n",
    "eval_ds  = RMPairsDataset(eval_data, tokenizer)\n",
    "\n",
    "import torch\n",
    "class RMDataCollator:\n",
    "    def __init__(self, tokenizer, max_len=512):\n",
    "        self.tok = tokenizer\n",
    "        self.max_len = max_len\n",
    "    def __call__(self, batch):\n",
    "        chosen  = [b[\"chosen_text\"]   for b in batch]\n",
    "        rejected= [b[\"rejected_text\"] for b in batch]\n",
    "        enc_ch = self.tok(chosen,   return_tensors=\"pt\", padding=True, truncation=True, max_length=self.max_len)\n",
    "        enc_rj = self.tok(rejected, return_tensors=\"pt\", padding=True, truncation=True, max_length=self.max_len)\n",
    "        return {\n",
    "            \"chosen_input_ids\": enc_ch[\"input_ids\"],\n",
    "            \"chosen_attention_mask\": enc_ch[\"attention_mask\"],\n",
    "            \"rejected_input_ids\": enc_rj[\"input_ids\"],\n",
    "            \"rejected_attention_mask\": enc_rj[\"attention_mask\"],\n",
    "        }\n",
    "\n",
    "collator = RMDataCollator(tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d7cd56",
   "metadata": {
    "id": "8tS8LcYFjY8K"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import GPT2Model, GPT2Config\n",
    "\n",
    "class GPT2RewardModel(nn.Module):\n",
    "    def __init__(self, pretrained_id=\"skt/kogpt2-base-v2\", gradient_checkpointing=False):\n",
    "        super().__init__()\n",
    "        self.backbone = GPT2Model.from_pretrained(pretrained_id)\n",
    "        if gradient_checkpointing:\n",
    "            self.backbone.gradient_checkpointing_enable()\n",
    "        hidden = self.backbone.config.n_embd\n",
    "        self.value_head = nn.Linear(hidden, 1)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        out = self.backbone(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        last_hidden = out.last_hidden_state\n",
    "        lengths = attention_mask.sum(dim=1) - 1  # [B]\n",
    "        pooled = last_hidden[torch.arange(input_ids.size(0)), lengths]  # [B,H]\n",
    "        reward = self.value_head(pooled).squeeze(-1)  # [B]\n",
    "        return reward\n",
    "\n",
    "\n",
    "def rm_step(model, batch, optimizer=None, device=\"cuda\"):\n",
    "    model = model.to(device)\n",
    "    for k in batch:\n",
    "        batch[k] = batch[k].to(device)\n",
    "    r_ch = model(batch[\"chosen_input_ids\"],   batch[\"chosen_attention_mask\"])\n",
    "    r_rj = model(batch[\"rejected_input_ids\"], batch[\"rejected_attention_mask\"])\n",
    "\n",
    "    diff = r_ch - r_rj\n",
    "    loss = -torch.log(torch.sigmoid(diff)).mean()\n",
    "    if optimizer:\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "    with torch.no_grad():\n",
    "        acc = (r_ch > r_rj).float().mean().item()\n",
    "    return loss.item(), acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b5ad00",
   "metadata": {
    "id": "YPZ-YHfWyNzJ"
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "rm_model = GPT2RewardModel(pretrained_id=base_id, gradient_checkpointing=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88cd489",
   "metadata": {
    "id": "2GHmyzKODo8d"
   },
   "outputs": [],
   "source": [
    "\n",
    "rm_model.backbone = get_peft_model(rm_model.backbone, cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596215f4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "b618b551983f48f7a702b2950d8fb397",
      "13d1ae56a3764f0ba37f08dbcc576495",
      "d335772272f449b9aee650cae34aec9a",
      "b9104da8cbcf4459869148a663097963",
      "c3c419fb9cf6483c902f1cc314d58ef5",
      "5acb2d2cf6aa4a4bb8a2b8290ae2c62e",
      "69a8ef7271cb4a5081d383392a4596cb",
      "d59e5bcad11d4f3b97d2f18833d9abc2",
      "4393065fd46d47cda0ede9cecc94be6e",
      "2a44f2fb25cb400f90017ba6dcf8fe1c",
      "f6740fbe4d9b46318a8d14f07d10399b",
      "62ffd2046eb5484aa9fff23c436036a8",
      "5d463dc00ef54151820c219035aa6656",
      "1241ee2e110c4e928f1b95d4906f214b",
      "3c2ee891fdc8489a9adc7186234ec76f",
      "ba3413184db4470d9d0ff1d5c4d355b4",
      "af25757c3f624a96a05ae2f9724a622b",
      "08b22f1a696d4612a6ef4d920713b23d",
      "6927bdff419a43ce81d4f052f770dd60",
      "7b76d6ae1ff042ac97f2fae9d5af4f97",
      "2bfe425e7f4f4acaab51650917425546",
      "43d3a6f1d4314633a0421c425ea52ea5"
     ]
    },
    "id": "br--ky43jjRG",
    "outputId": "da77ad44-f39d-4983-97b5-78d97ec3ed4a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Epoch 1 [train]:   0%|          | 0/3364 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 1 [eval]:   0%|          | 0/374 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "opt = torch.optim.AdamW(rm_model.parameters(), lr=2e-5, weight_decay=0.01)\n",
    "train_loader = DataLoader(train_ds, batch_size=8, shuffle=True, collate_fn=collator)\n",
    "eval_loader  = DataLoader(eval_ds,  batch_size=8, shuffle=False, collate_fn=collator)\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "\n",
    "steps_per_epoch = len(train_loader)\n",
    "total_steps = steps_per_epoch * 2\n",
    "\n",
    "for epoch in range(1):\n",
    "    rm_model.train()\n",
    "    tot_loss = tot_acc = 0\n",
    "    t0 = time.time()\n",
    "\n",
    "    pbar = tqdm(enumerate(train_loader), total=steps_per_epoch, desc=f\"Epoch {epoch+1} [train]\")\n",
    "    for step, batch in pbar:\n",
    "        loss, acc = rm_step(rm_model, batch, optimizer=opt, device=device)\n",
    "        tot_loss += loss\n",
    "        tot_acc  += acc\n",
    "\n",
    "        avg_loss = tot_loss / (step + 1)\n",
    "        avg_acc  = tot_acc / (step + 1)\n",
    "\n",
    "        pbar.set_postfix({\"loss\": f\"{avg_loss:.4f}\", \"acc\": f\"{avg_acc:.3f}\"})\n",
    "\n",
    "    rm_model.eval()\n",
    "    eval_loss = eval_acc = 0\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(enumerate(eval_loader), total=len(eval_loader), desc=f\"Epoch {epoch+1} [eval]\")\n",
    "        for step, batch in pbar:\n",
    "            loss, acc = rm_step(rm_model, batch, optimizer=None, device=device)\n",
    "            eval_loss += loss\n",
    "            eval_acc  += acc\n",
    "\n",
    "            avg_loss = eval_loss / (step + 1)\n",
    "            avg_acc  = eval_acc / (step + 1)\n",
    "\n",
    "            pbar.set_postfix({\"loss\": f\"{avg_loss:.4f}\", \"acc\": f\"{avg_acc:.3f}\"})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228f8c45",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jqiv0p8w0E8I",
    "outputId": "28ccaed9-4015-4e93-a4e3-1c4ca9e3eedd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ RM сохранена в: /home/jovyan/output_RM\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "SAVE_DIR = Path.cwd() / \"output_RM\"   # Или Path.home() / \"output_RM\"\n",
    "SAVE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "rm_model.backbone.save_pretrained(SAVE_DIR)\n",
    "\n",
    "tokenizer.save_pretrained(SAVE_DIR)\n",
    "\n",
    "torch.save(rm_model.value_head.state_dict(), os.path.join(SAVE_DIR, \"value_head.bin\"))\n",
    "\n",
    "print(\"✅ RM сохранена в:\", SAVE_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf472af9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wc7eZ_LwmHDN",
    "outputId": "41383ce2-18e4-4215-fcdc-a5b6fe6d38ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pairwise] Acc=0.746 | mean_margin=0.561 | median_margin=0.825\n"
     ]
    }
   ],
   "source": [
    "import torch, numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "rm_model.eval()\n",
    "rm_model.to(device)\n",
    "\n",
    "eval_loader_pairs = DataLoader(eval_ds, batch_size=32, shuffle=False, collate_fn=RMDataCollator(tokenizer))\n",
    "\n",
    "def tensor1d(x):\n",
    "    if isinstance(x, tuple): x = x[0]\n",
    "    x = x.squeeze(-1)\n",
    "    return x\n",
    "\n",
    "tot, correct, margins = 0, 0, []\n",
    "with torch.no_grad():\n",
    "    for batch in eval_loader_pairs:\n",
    "        ch_ids = batch[\"chosen_input_ids\"].to(device)\n",
    "        ch_ms  = batch[\"chosen_attention_mask\"].to(device)\n",
    "        rj_ids = batch[\"rejected_input_ids\"].to(device)\n",
    "        rj_ms  = batch[\"rejected_attention_mask\"].to(device)\n",
    "\n",
    "        r_ch = tensor1d(rm_model(ch_ids, ch_ms)).cpu().numpy()  # [B]\n",
    "        r_rj = tensor1d(rm_model(rj_ids, rj_ms)).cpu().numpy()  # [B]\n",
    "        diff = r_ch - r_rj\n",
    "        margins.extend(diff.tolist())\n",
    "        correct += (diff > 0).sum()\n",
    "        tot += diff.shape[0]\n",
    "\n",
    "pair_acc = correct / tot\n",
    "print(f\"[Pairwise] Acc={pair_acc:.3f} | mean_margin={np.mean(margins):.3f} | median_margin={np.median(margins):.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91b0504",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iBAtnAtfoeXc",
    "outputId": "d4dce0e2-c01d-4860-e662-c11b49cf55e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Prompt]\n",
      "서울에서 주말에 아이와 갈 만한 실내 체험 활동 추천해줘\n",
      "\n",
      "#1  reward=1.047\n",
      "저는 인공지능이기 때문에 추천이 불가능합니다.\n",
      "\n",
      "#2  reward=0.985\n",
      "알려드릴 수 없습니다.\n",
      "\n",
      "#3  reward=0.916\n",
      "아이 연령대에 따라 다르지만, 5~7세라면 코엑스 키자니아 같은 체험형 공간이 적합합니다.\n",
      "\n",
      "#4  reward=0.812\n",
      "모릅니다.\n",
      "\n",
      "#5  reward=0.778\n",
      "서울에는 다양한 체험 공간이 있어요. 인터넷 검색해보시면 많은 정보를 얻을 수 있습니다.\n",
      "\n",
      "#6  reward=0.776\n",
      "추천드릴 수는 없지만 서울에는 어린이들을 위한 좋은 장소가 많습니다.\n",
      "\n",
      "#7  reward=0.687\n",
      "서울 어린이대공원 동물원이나 놀이시설도 추천해요. 입장료가 저렴해서 가족 단위 방문객이 많습니다.\n",
      "\n",
      "#8  reward=0.541\n",
      "아이와 함께라면 실내 전시관이나 놀이시설이 무난합니다.\n",
      "\n",
      "#9  reward=0.417\n",
      "날씨가 좋으면 잠실 롯데월드타워 전망대, 실내활동이면 국립중앙박물관 어린이박물관도 좋아요.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def score_candidates(prompt, candidates, tokenizer, rm_model, max_len=512, topk=None):\n",
    "    rm_model.eval()\n",
    "    texts = [format_sample(prompt, c) for c in candidates]\n",
    "    enc = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=max_len)\n",
    "    with torch.no_grad():\n",
    "        rewards = tensor1d(rm_model(enc[\"input_ids\"].to(device), enc[\"attention_mask\"].to(device))).cpu().numpy()\n",
    "    order = np.argsort(-rewards)\n",
    "    print(f\"\\n[Prompt]\\n{prompt}\\n\")\n",
    "    for rank, idx in enumerate(order[:topk] if topk else order, 1):\n",
    "        print(f\"#{rank}  reward={rewards[idx]:.3f}\\n{candidates[idx]}\\n\")\n",
    "    return rewards, order\n",
    "\n",
    "\n",
    "my_prompt = \"서울에서 주말에 아이와 갈 만한 실내 체험 활동 추천해줘\"\n",
    "my_candidates = [\n",
    "\n",
    "    \"서울 어린이대공원 동물원이나 놀이시설도 추천해요. 입장료가 저렴해서 가족 단위 방문객이 많습니다.\",\n",
    "    \"날씨가 좋으면 잠실 롯데월드타워 전망대, 실내활동이면 국립중앙박물관 어린이박물관도 좋아요.\",\n",
    "    \"아이 연령대에 따라 다르지만, 5~7세라면 코엑스 키자니아 같은 체험형 공간이 적합합니다.\",\n",
    "\n",
    "    \"서울에는 다양한 체험 공간이 있어요. 인터넷 검색해보시면 많은 정보를 얻을 수 있습니다.\",\n",
    "    \"추천드릴 수는 없지만 서울에는 어린이들을 위한 좋은 장소가 많습니다.\",\n",
    "    \"아이와 함께라면 실내 전시관이나 놀이시설이 무난합니다.\",\n",
    "\n",
    "\n",
    "    \"저는 인공지능이기 때문에 추천이 불가능합니다.\",\n",
    "    \"알려드릴 수 없습니다.\",\n",
    "    \"모릅니다.\"\n",
    "]\n",
    "_ = score_candidates(my_prompt, my_candidates, tokenizer, rm_model, max_len=512, topk=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9108ad",
   "metadata": {
    "id": "R37-9sPnuzyq"
   },
   "source": [
    "기존 GPTRM_custom에서 단순히 GPT2Model + value_head 구조였는데, 지금은 GPT2RewardModel과 LoRA/gradient checkpointing 같은 설정을 적용 가능하게 수정."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ada423",
   "metadata": {
    "id": "pleIJD1Uu1iX",
    "outputId": "0458fd39-feae-47ed-966a-c8a72a06c677"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/output_RM_backup.zip'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "\n",
    "folder = \"output_RM\"\n",
    "\n",
    "shutil.make_archive(\"output_RM_backup\", 'zip', folder)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
